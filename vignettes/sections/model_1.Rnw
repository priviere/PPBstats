\subsection{model\_1 to perform mean comparisons on farms }
\label{model_1}

At the farm level, the residual had few degrees of freedom, leading to a poor estimation of the residual variance and to a lack of power for comparing populations.
Hence, model\_1 was implemented (section~\ref{section_model1}).
For model\_1, it gave nice results with more than 20 environment \citep{riviere_hierarchical_2015}.

\subsubsection{Theory of the model}

The model is describe in \citet{riviere_hierarchical_2015}.
We restricted ourselves to analysing plot means.
The phenotypic value $Y_{ijk}$ for variable $Y$, germplasm $i$, environment $j$ and block $k$ was modelled as :

\begin{equation}
	Y_{ijk} = \mu_{ij} + \beta_{jk} + \varepsilon_{ijk} ; \quad \varepsilon_{ijk} \sim \mathcal{N} (0,\sigma^2_{j}),
	\label{model1}
\end{equation}

where
$\mu_{ij}$ was the mean of germplasm $i$ in environment $j$ (note that this parameter, which corresponds to an entry, confounds the population effect and the population $\times$ environment effect);
$\beta_{jk}$ was the effect of block $k$ in environment $j$ satisfying the constraint\footnote{Note that it is quite different from \citet{riviere_hierarchical_2015} where the model was done only for two blocks. Here there is no restriction on the number of blocks.} $\sum\limits_{k=1}^K \beta_{jk} = 1$ ;
$\varepsilon_{ijk}$ was the residual error;
$\mathcal{N} (0,\sigma^2_{j})$ denoted normal distribution centred on 0 with variance $\sigma^2_{j}$, which was specific to environment $j$.

We took advantage of the similar structure of the trials on each environment of the network to assume that trial residual variances came from a common distribution :

\begin{displaymath}
	\sigma^2_{j} \sim \frac{1}{Gamma(\nu,\rho)},
\end{displaymath}

where $\nu$ and $\rho$ are unknown parameters.
Because of the low number of residual degrees of freedom for each farm, we used a hierarchical approach in order to assess mean differences on farm.
For that, we placed vague prior distributions on the hyperparameters $\nu$ and $\rho$ :

\begin{displaymath}
	\nu \sim Uniform(\nu_{min},\nu_{max}) ; \quad \rho \sim Gamma(10^{-6},10^{-6}).
\end{displaymath}


In other words, the residual variance of a trial within environment was estimated using all the informations available on the network rather than using the data from that particular trial only.

The parameters $\mu_{ij}$ and $\beta_{j1}$ were assumed to follow vague prior distributions~:

\begin{displaymath}
	\mu_{ij} \sim \mathcal{N}(\mu_{.j},10^{6}); \quad \beta_{j1} \sim \mathcal{N}(0,10^{6}).
\end{displaymath}


The inverse gamma distribution has a support bounded by 0 (consistent with the definition of a variance) and may have various shapes including asymmetric distributions.
From an agronomical point of view, the assumption that trial variances were heterogeneous was consistent with organic farming: there were as many environments as farmers leading to a high heterogeneity.
Environment was here considered in a broad sense: practices (sowing date, sowing density, tilling, etc.), pedo climatic conditions, biotic and abiotic stress, \dots \citep{desclaux_changes_2008}.
Moreover, the inverse gamma distribution had conjugate properties that facilitated MCMC convergence.
This model was therefore a good choice based on both agronomic and statistical criteria.

The residual variance estimated from the controls was assumed to be representative of the residual variance of the other entries.
Blocks were included in the model only if the trial had blocks.

\subsubsection{Steps with \pack}

For model\_1, you can follow these steps (Figure \ref{main_workflow}):

\begin{enumerate}
\item Run the model with \texttt{model\_1}
\item Check model outputs with graphs to know if you can continue the analysis with \texttt{check\_model}
\item Get mean comparisons for each factor with \texttt{mean\_comparisons} and vizualise it with \texttt{plot}
\end{enumerate}

Let's get the data.
The values for $\mu_{ij}$, $\beta_{jk}$, $\epsilon_{ijk}$ and $\sigma_j$ are the real value taken to create the dataset.
This dataset is representative of data you can get in a PPB programme.

<<message=TRUE,cache=FALSE>>=
data(data_model_1)
head(data_model_1)
@

\subsubsection{Run the model}

To run model~\ref{model1} on the dataset, used the function \texttt{model\_1}.
You can run it on one variable.
Here it is thousand kernel weight (tkw).

By default, \texttt{model\_1} returns posteriors for 
$\mu_{ij}$ (\texttt{return.mu = TRUE}), 
$\beta_{jk}$ (\texttt{return.beta = TRUE}), 
$\sigma_j$ (\texttt{return.sigma = TRUE}), 
$\nu$ (\texttt{return.nu = TRUE}) and 
$\rho$ (\texttt{return.rho = TRUE}).
You can also get $\epsilon_{ijk}$ value with \texttt{return.espilon = TRUE}.

By default, DIC is not displayed, you may want this value to compare to other model (\texttt{DIC = TRUE}).
DIC criterion is a generalization of the AIC criterion that can be used for hierarchical models \citep{spiegelhalter_bayesian_2002}.
The smaller the DIC value, the better the model \citep{plummer_penalized_2008}.

<<message=TRUE,cache=FALSE>>=
# out_model_1 = model_1(data = data_model_1, variable = "tkw", return.epsilon = TRUE)

# Compiling model graph
# Resolving undeclared variables
# Allocating nodes
# Graph information:
#   Observed stochastic nodes: 976
# Unobserved stochastic nodes: 927
# Total graph size: 8609
# 
# Initializing model
# 
# |++++++++++++++++++++++++++++++++++++++++++++++++++| 100%
# |**************************************************| 100%
# |**************************************************| 100%
# |**************************************************| 100%

load("./data_PPBstats/out_model_1.RData") # To save time
@

You can get informations of the environments in the dataset :

<<message=TRUE,cache=FALSE>>=
out_model_1$vec_env_with_no_data
 
out_model_1$vec_env_with_no_controls
 
out_model_1$vec_env_with_controls
 
out_model_1$vec_env_RF
 
out_model_1$vec_env_SF
@

Below is an example with low \texttt{nb\_iterations}:
<<message=TRUE,cache=FALSE>>=
# out_model_1_bis = model_1(data = data_model_1, variable = "tkw", nb_iteration = 5000)

# Compiling model graph
# Resolving undeclared variables
# Allocating nodes
# Graph information:
#   Observed stochastic nodes: 976
# Unobserved stochastic nodes: 927
# Total graph size: 8609
# 
# Initializing model
# 
# |++++++++++++++++++++++++++++++++++++++++++++++++++| 100%
# |**************************************************| 100%
# |**************************************************| 100%
# Warning message:
#   In model_1(data = data_model_1, variable = "tkw", nb_iteration = 5000) :
#   nb_iterations is below 20 000, which seems small to get convergence in the MCMC.

load("./data_PPBstats/out_model_1_bis.RData") # To save time
@

\subsubsection{Check and visualize model outputs}

\paragraph{Check the model}

Once the model is run, it is necessary to check if the outputs can be taken with confidence.
This step is needed before going ahead in the analysis (in fact, object used in the next functions must come from \texttt{check\_model}).

<<message=TRUE,cache=FALSE>>=
# out_check_model_1 = check_model(out_model_1)

# The Gelman-Rubin test is running for each parameter ...
# The two MCMC for each parameter converge thanks to the Gelman-Rubin test.

load("./data_PPBstats/out_check_model_1.RData") # To save time
@

\texttt{out\_check\_model\_1} is a list containing:

\begin{itemize}
\item \texttt{MCMC} : a data fame resulting from the concatenation of the two MCMC for each parameter. This object can be used for further analysis. There are as many columns than parameters and as many rows than iterations/thin (the thin value is 10 by default in the models).
<<message=TRUE,cache=FALSE>>=
dim(out_check_model_1$MCMC)
@

\item \texttt{MCMC\_conv\_not\_ok}: a data fame resulting from the concatenation of the two MCMC for each parameter for environment where  some parameters did not converge for mu and beta

\item \texttt{data\_env\_with\_no\_controls} : data frame with environnement with no controls

\item \texttt{data\_env\_whose\_param\_did\_not\_converge} : a list with data frame with environments where some parameters did not converge for mu and beta

\item \texttt{data\_ggplot} : a list containing information for ggplot:
\begin{itemize}
\item \texttt{sigma\_j}
\item \texttt{mu\_ij}
\item \texttt{beta\_jk}
\item \texttt{sigma\_j\_2}
\item \texttt{epsilon\_ijk}
\end{itemize}

\end{itemize}

When considering \texttt{out\_model\_1\_bis}:
<<message=TRUE,cache=FALSE>>=
# out_check_model_1_bis = check_model(out_model_1_bis)

# The Gelman-Rubin test is running for each parameter ...
# The two MCMC of the following parameters do not converge thanks to the Gelman-Rubin test : nu, rho, sigma[env2-2:2010]. Therefore, they are not present in MCMC output.
# MCMC are updated, the following environment were deleted : env2-2:2010
# data_env_whose_param_did_not_converge contains the raw data for these environments.

load("./data_PPBstats/out_check_model_1_bis.RData") # To save time
@


\paragraph{Visualize outputs}

Once the computation is done, you can visualize the results with \texttt{plot}
<<message=TRUE,cache=FALSE>>=
p_out_check_model_1 = plot(out_check_model_1)
@

\texttt{p\_out\_check\_model\_1} is a list with:

\begin{itemize}

\item \texttt{sigma\_j\_gamma} : mean of each \texttt{sigma\_j} displayed on the Inverse Gamma distribution. The first graph represent all the \texttt{sigma\_j}, the other graph represent \texttt{nb\_parameters\_per\_plot} \texttt{sigma\_j} per graph.
<<message=TRUE,cache=FALSE>>=
p_out_check_model_1$sigma_j_gamma[[1]]
p_out_check_model_1$sigma_j_gamma[[2]]
@

\item \texttt{mu\_ij} : distribution of each \texttt{mu\_ij} in a list with as many elements as environment. For each element of the list, there are as many graph as needed with \texttt{nb\_parameters\_per\_plot} \texttt{mu\_ij} per graph.
<<message=TRUE,cache=FALSE>>=
names(p_out_check_model_1$mu_ij)

names(p_out_check_model_1$mu_ij$`env1-1:2010`)

p_out_check_model_1$mu_ij$`env1-1:2010`$`1`
@

\item \texttt{beta\_jk} : distribution of each \texttt{beta\_jk} in a list with as many elements as environment. For each element of the list, there are as many graph as needed with \texttt{nb\_parameters\_per\_plot} \texttt{beta\_jk} per graph.
<<message=TRUE,cache=FALSE>>=
names(p_out_check_model_1$beta_jk)

names(p_out_check_model_1$beta_jk$`env1-1:2010`)

p_out_check_model_1$beta_jk$`env1-1:2010`$`1`
@


\item \texttt{sigma\_j} : distribution of each \texttt{sigma\_j}. There are as many graph as needed with \texttt{nb\_parameters\_per\_plot} \texttt{sigma\_j} per graph.
<<message=TRUE,cache=FALSE>>=
names(p_out_check_model_1$sigma_j)

p_out_check_model_1$sigma_j[[1]]
@


\item \texttt{epsilon\_ijk} : standardised residuals distribution.
If the model went well it should be between -2 and 2.
<<message=TRUE,cache=FALSE>>=
p_out_check_model_1$epsilon_ijk
@

\item \texttt{mcmc\_not\_converge\_traceplot\_density} : a list with the plots of trace and density to check the convergence of the two MCMC only for chains that are not converging thanks to the Gelman-Rubin test. 
If all the chains converge, it is NULL
<<message=TRUE,cache=FALSE>>=
p_out_check_model_1$mcmc_not_converge_traceplot_density
@
Here all the parameters converge.


When considering \texttt{p\_out\_check\_model\_1\_bis}, there is no convergence because the MCMC are too small.

<<message=TRUE,cache=FALSE>>=
p_out_check_model_1_bis = plot(out_check_model_1_bis)

p_out_check_model_1_bis$mcmc_not_converge_traceplot_density$`sigma\\[env2-2:2010`
@

\end{itemize}

Just for fun, you can compare the posterior medians and the arithmetic means for the \texttt{mu\_ij}.

<<message=TRUE,cache=FALSE>>=
MCMC = out_check_model_1$MCMC
effects = apply(MCMC, 2, median)
mu_ij_estimated = effects[grep("mu",names(effects))]
names(mu_ij_estimated) = sapply(names(mu_ij_estimated), 
                                function(x){  sub("\\]", "", sub("mu\\[", "", x)) } 
                                )

d = filter(data_model_1, location != "env4")
d = filter(d, location != "env5")
d = droplevels(d)
environment = paste(as.character(d$location), as.character(d$year), sep = ":")
d$entry = as.factor(paste(as.character(d$germplasm), environment, sep = ","))
mu_ij = tapply(d$mu_ij, d$entry, mean, na.rm = TRUE)

check_data = cbind.data.frame(mu_ij, mu_ij_estimated[names(mu_ij)])
@

Let's have a look on the relation between the posterior medians and the arithmetic means.
It goes pretty well!

\begin{figure}[H]
<<message=TRUE,cache=FALSE,out.width=".6\\textwidth">>=
p = ggplot(check_data, aes(x = mu_ij, y = mu_ij_estimated))
p + stat_smooth(method = "lm") + geom_point()
@
\end{figure}



\subsubsection{Get and visualize mean comparisons}

\paragraph{Get mean comparisons}

Get mean comparisons with \texttt{mean\_comparisons}.
The theory behind mean comparisons are explained in Section~\ref{mean_comp}.

Below is an example for $\mu$, the same can be done for $\beta$.

<<message=TRUE,cache=FALSE>>=
# out_mean_comparisons_model_1_mu = mean_comparisons(out_check_model_1, parameter = "mu")

# Get at least X groups for env2-1:2011. It may take some time ...
# Get at least X groups for env2-1:2011 is done.
# Get at least X groups for env2-13:2011. It may take some time ...
# Get at least X groups for env2-13:2011 is done.
# Get at least X groups for env2-3:2012. It may take some time ...
# Get at least X groups for env2-3:2012 is done.
# Get at least X groups for env2-9:2010. It may take some time ...
# Get at least X groups for env2-9:2010 is done.

load("./data_PPBstats/out_mean_comparisons_model_1_mu.RData") # To save time
@

\texttt{out\_mean\_comparisons\_model\_1\_mu} is a list of three elements:
\begin{itemize}
\item \texttt{data\_mean\_comparisons} a list with as many elements as environment.

<<message=TRUE,cache=FALSE>>=
head(names(out_mean_comparisons_model_1_mu$data_mean_comparisons))
@

Each element of the list is composed of two elements:

\begin{itemize}
\item \texttt{mean.comparisons}
<<message=TRUE,cache=FALSE>>=
head(out_mean_comparisons_model_1_mu$data_mean_comparisons$`env1-1:2010`$mean.comparisons)
@

\item \texttt{Mpvalue} : a square matrix with pvalue computed for each pair of parameter.
<<message=TRUE,cache=FALSE>>=
out_mean_comparisons_model_1_mu$data_mean_comparisons$`env1-1:2010`$Mpvalue[1:3, 1:3]
@

\end{itemize}

\item \texttt{data\_env\_with\_no\_controls} a list with as many elements as environment.
<<message=TRUE,cache=FALSE>>=
names(out_mean_comparisons_model_1_mu$data_env_with_no_controls)
@

In each list it is mean.comparisons
<<message=TRUE,cache=FALSE>>=
head(out_mean_comparisons_model_1_mu$data_env_with_no_controls$`env5:2010`$mean.comparisons)
@

\item \texttt{data\_env\_whose\_param\_did\_not\_converge} a list with as many elements as environment.
<<message=TRUE,cache=FALSE>>=
names(out_mean_comparisons_model_1_mu$data_env_whose_param_did_not_converge)
@
Here it is NULL as all parameters converge. 
Otherwise in each list it is mean.comparisons.
<<message=TRUE,cache=FALSE>>=
head(out_mean_comparisons_model_1_mu$data_env_with_no_controls$`env5:2010`$mean.comparisons)
@

\end{itemize}


\paragraph{Visualize mean comparisons}

To see the output, use \texttt{plot}.
On each plot, the \texttt{alpha} (type one error) value and the alpha correction are displayed.
\texttt{alpha = Imp} means that no differences were possible to find.
For \texttt{ggplot.type = "interaction"} and \texttt{ggplot.type = "score"}, it is display under the form: \texttt{alpha | alpha correction}.

The ggplot are done for each element of the list coming rom \texttt{mean\_comparisons}.

For each ggplot.type, it is a list of three elements being lists with as many elements as environment. 

For each element of the list, there are as many graph as needed with \texttt{nb\_parameters\_per\_plot} parameters per graph.

\subparagraph{barplot}

<<message=TRUE,cache=FALSE>>=
p_barplot_mu = plot(out_mean_comparisons_model_1_mu, ggplot.type = "barplot")
names(p_barplot_mu)
@

From \texttt{data\_mean\_comparisons}, only environments where all MCMC converge are represented.

Letters are displayed on each bar. Parameters that do not share the same letters are different regarding type I error (alpha) and alpha correction. 

The error I (alpha) and the alpha correction are displayed in the title. 
alpha = Imp means that no differences were possible to find.

<<message=TRUE,cache=FALSE>>=
p = p_barplot_mu$data_mean_comparisons

head(names(p))

p_env = p$`env1-1:2010`
names(p_env)

p_env$`1`
p_env$`2`
p_env$`3`
p_env$`4`
@

For \texttt{data\_env\_with\_no\_controls}, only environments where there were no controls are represented.

<<message=TRUE,cache=FALSE>>=
p_barplot_mu$data_env_with_no_controls
@


For \texttt{data\_env\_whose\_param\_did\_not\_converge}, only environments where MCMC did not converge are represented.

<<message=TRUE,cache=FALSE>>=
p_barplot_mu$data_env_whose_param_did_not_converge
@


Regarding pairs of entries in a given environment, 
it is possible to get comparison of paris of entries in a given location.
This is useful if you want to compare two versions within a group.
For exemple:
<<message=TRUE,cache=FALSE,out.width=".6\\textwidth">>=
data(data_version)
head(data_version)
@

Here, in location \texttt{env1-1}, \texttt{tem-1} and \texttt{tem-2} are two version belonging to the same groupe.

Lets' make the plots:
<<message=TRUE,cache=FALSE>>=
p_barplot_mu_version = plot(
  out_mean_comparisons_model_1_mu,
  data_version = data_version,
  ggplot.type = "barplot"
)
p_barplot_mu_version$data_mean_comparisons$`env1-1:2010`
@

The stars corresponds to the pvalue:

\begin{center}
\begin{tabular}{cc}
\hline
pvalue & stars \\
\hline
$< 0.001$ & *** \\
$[0.001 , 0.05]$ & ** \\
$[0.05 , 0.01]$ & * \\
$> 0.01$ & . \\
\hline
\end{tabular}
\end{center}

The pvalue is computed as describe in Section~\ref{mean_comp} if the parameters have been estimated with the model.

For environments where MCMC did not converge or without environments, it is a \texttt{t.test} which is perform.

<<message=TRUE,cache=FALSE,out.width=".6\\textwidth">>=
p_barplot_mu_version$data_env_with_no_controls
@

<<message=TRUE,cache=FALSE,out.width=".6\\textwidth">>=
p_barplot_mu_version$data_env_whose_param_did_not_converge
@

\subparagraph{interaction}

With \texttt{ggplot.type = "interaction"}, you can display the year effect as well as detect groups.
One group is represented by one vertical line.
Germplasms which share the same group are not different.
Germplasms which do not share the same groupe are different (Section~\ref{mean_comp}).

The ggplot are done for each element of the list coming rom \texttt{mean\_comparisons}.

For each ggplot.type, it is a list of three elements being lists with as many elements as environment. 

For each element of the list, there are as many graph as needed with \texttt{nb\_parameters\_per\_plot} parameters per graph.


<<message=TRUE,cache=FALSE>>=
p_interaction = plot(out_mean_comparisons_model_1_mu, ggplot.type = "interaction")

head(names(p_interaction$data_mean_comparisons))

p_env = p_interaction$data_mean_comparisons$`env1-1`
names(p_env)

p_env$`1`
p_env$`2`
p_env$`3`
p_env$`4`

@


\subparagraph{score}

For the score, more entries are displayed.
An high score means that the entry was in a group with an high mean.
A low socre means that the entry was in a group with an low mean.
This plot is useful to look at year effects.

<<message=TRUE,cache=FALSE>>=
p_score = plot(out_mean_comparisons_model_1_mu, ggplot.type = "score")

head(names(p_score))

p_env = p_score$`env1-1`
names(p_env)

p_env$`1`
p_env$`2`
p_env$`3`
p_env$`4`

@

\subsubsection{Apply the workflow to several variables}

If you wish to apply the model\_1 workflow to several variables, you can use \texttt{lapply} with the following code :

<<message=TRUE,cache=FALSE>>=
workflow_model_1 = function(x){
  out_model_1 = model_1(data = data_model_1, variable = x, return.epsilon = TRUE)
  
  out_check_model_1 = check_model(out_model_1)
  p_out_check_model_1 = plot(out_check_model_1)
  
  out_mean_comparisons_model_1_mu = mean_comparisons(out_check_model_1, parameter = "mu")
  p_barplot_mu = plot(out_mean_comparisons_model_1_mu, ggplot.type = "barplot")
  p_interaction = plot(out_mean_comparisons_model_1_mu, ggplot.type = "interaction")
  p_score = plot(out_mean_comparisons_model_1_mu, ggplot.type = "score")
  
  out = list(
    "out_model_1" = out_model_1,
    "out_check_model_1" = out_check_model_1,
    "p_out_check_model_1" = p_out_check_model_1,
    "out_mean_comparisons_model_1_mu" = out_mean_comparisons_model_1_mu,
    "p_barplot_mu" = p_barplot_mu,
    "p_interaction" = p_interaction,
    "p_score" = p_score
    )
  return(out)
}

## Not run because of memory and time issues !
# vec_variables = c("y1", "y2", "y3")
#
# out = lapply(vec_variables, workflow_model_1)
# names(out) = vec_variables

@


